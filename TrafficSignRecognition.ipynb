{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashking1981/lb_training/blob/master/TrafficSignRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu1DXCwOio-d"
      },
      "source": [
        "## Traffic Sign Recognition with Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NzZKV7tlPCw"
      },
      "source": [
        "The goal is to build a model that can detect and classify traffic signs in a video stream taken from a moving car. Given an image of a traffic sign, our model should be able to tell it's type (*e.g. Stop sign, speed limit, yield sign*). We'll work with images that are properly cropped such that the traffic sign takes most of the image. So don't worry about edge cases as of now.\n",
        "\n",
        "You are free to use either Keras or Pytorch.\n",
        "\n",
        "Send the code to amritansh@learnbay.co"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNDMv4nAi9I-"
      },
      "source": [
        "We will use the **Belgian Traffic Sign** Dataset because it is big enough to train on, and yet small enough to be easy to work with.\n",
        "\n",
        "You can download the dataset from : https://btsd.ethz.ch/shareddata/\n",
        "\n",
        "There are a lot of datasets on that page, but you only need the two files listed under BelgiumTS for Classification (cropped images):\n",
        "\n",
        "\n",
        "\n",
        "1.   BelgiumTSC_Training (https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Training.zip)\n",
        "2.   BelgiumTSC_Testing (https://btsd.ethz.ch/shareddata/BelgiumTSC/BelgiumTSC_Testing.zip)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPZhWd7pjqEo"
      },
      "source": [
        "The images in this dataset are in an old .ppm format. So old, in fact, that most tools don’t support it. Which meant that we cann’t casually browse the folders to take a look at the images. Luckily, the Scikit Image library recognizes this format. This code below will load the data and return two lists: images and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4OZlQPklN_N"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import skimage.data\n",
        "import skimage.transform\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.keras\n",
        "\n",
        "# Allow image embeding in notebook\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfYEexYXlxNW"
      },
      "source": [
        "### Parse and load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gi28Dslih_v"
      },
      "source": [
        "def load_data(data_dir):\n",
        "    # Get all subdirectories of data_dir. Each represents a label.\n",
        "    directories = [d for d in os.listdir(data_dir)\n",
        "                   if os.path.isdir(os.path.join(data_dir, d))]\n",
        "\n",
        "    # Loop through the label directories and collect the data in\n",
        "    # two lists, labels and images.\n",
        "    labels = []\n",
        "    images = []\n",
        "    for d in directories:\n",
        "        label_dir = os.path.join(data_dir, d)\n",
        "        file_names = [os.path.join(label_dir, f)\n",
        "                      for f in os.listdir(label_dir)\n",
        "                      if f.endswith(\".ppm\")]\n",
        "        for f in file_names:\n",
        "            images.append(skimage.io.imread(f))\n",
        "            labels.append(int(d))\n",
        "    return images, labels # these provide you data in numpy arrays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dItZg1_FmEJI"
      },
      "source": [
        "\n",
        "   ** images** :  a list of images, each image is represted by a numpy array.\n",
        "   \n",
        "  **labels** :  a list of labels. Integers with values between 0 and 61.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJVor7G4l3iY"
      },
      "source": [
        "# Load training and testing datasets.\n",
        "ROOT_PATH = \"/\" # your root path\n",
        "train_data_dir = os.path.join(ROOT_PATH, \"datasets/BelgiumTS/Training\")\n",
        "test_data_dir = os.path.join(ROOT_PATH, \"datasets/BelgiumTS/Testing\")\n",
        "\n",
        "images, labels = load_data(train_data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viT-aEJol27q"
      },
      "source": [
        "### Explore the Dataset\n",
        "\n",
        "How many images and labels does it have?\n",
        "\n",
        "Display the first image of each label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MVd7pFImosl"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRWX1KI3kkNa"
      },
      "source": [
        "### Handling images of different sizes\n",
        "\n",
        "Ideally neural networks expect a fixed-size input. But these images are not all the same size. A common approach is to crop and pad the images to a selected apect ratio, but then we have to make sure that we don't cut-off parts of the traffic signs in the process. That seems like it might require manual work!\n",
        "\n",
        "We'll just resize the images to a fixed size and ignore the distortions caused by the different aspect ratios. A person can easily recognize a traffic sign even if it's compressed or stretched a bit, so we hope that our model can as well.\n",
        "\n",
        "And while we're at it, let's make the images smaller. The larger the input data, the larger the model, and the slower it is to train. In the early stages of development we want fast training to avoid long waits between iterations while we change the code rapidly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQJD3SLgnHEx"
      },
      "source": [
        "# Resize images\n",
        "images64 = [skimage.transform.resize(image, (64, 64), mode='constant')\n",
        "                for image in images]\n",
        "display_images_and_labels(images64, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs80KOl5nS7P"
      },
      "source": [
        "### Create a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUxtY_monSku"
      },
      "source": [
        "# your code here. One could design from scratch or use some standard ConvNets provided in Keras and train it from scratch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buk2thsMnhsK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6j1Ahy5nYUj"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTrjrOslnZNz"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrpPwSnsnd8o"
      },
      "source": [
        "### Using the Model to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xk-5NaUnmEB"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fl9Ye6anneP"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Time to  test with validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7CYBwjMnuGt"
      },
      "source": [
        "# Load the test dataset.\n",
        "test_images, test_labels = load_data(test_data_dir)\n",
        "# Transform the images, just like we did with the training set.\n",
        "test_images64 = [skimage.transform.resize(image, (64, 64), mode='constant')\n",
        "                 for image in test_images]\n",
        "display_images_and_labels(test_images64, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize using tensorboard"
      ],
      "metadata": {
        "id": "xHZS_Vzb2KPr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}